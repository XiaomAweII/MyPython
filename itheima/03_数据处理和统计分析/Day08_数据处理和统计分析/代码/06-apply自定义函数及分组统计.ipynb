{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 导包"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "677b786798ef6ece"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "757be3f998292c0c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 细节, 切换下相对路径"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d175167c8a62a0ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 手动修改 工作空间目录, 即: 修改相对路径的地址\n",
    "os.chdir('D:/workspace/ai_20_work_bj/pandasProject/')\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f54641877167b85"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. apply()函数使用"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bca144633d446e8d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 apply函数作用于 Series对象"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d976d87c58f775e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. 创建df对象, 给两列值.\n",
    "df = pd.DataFrame({'a': [10, 20, 30], 'b': [20, 30, 40]})\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "585967bfe507252c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. 演示apply()函数, 操作Series对象.\n",
    "# 需求1: 自定义函数my_func1(), 实现接收Series对象, 然后使其每个值变成 其平方结果.\n",
    "def my_func1(x):\n",
    "    return x ** 2\n",
    "\n",
    "\n",
    "# 传入Series对象, 调用my_func()函数.\n",
    "# 细节: apply()函数会把 my_func1()函数作用到 Series的每个对象.\n",
    "df.a.apply(my_func1)  # 细节: 不加小括号, 传入的是函数对象."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27181fd42c65375f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 需求2: apply传入, 需要多个参数的函数. 例如: 自定义函数my_func2(x, e), 实现计算 x的e次方\n",
    "def my_func2(x, e):\n",
    "    return x ** e\n",
    "\n",
    "\n",
    "# Series调用上述的函数\n",
    "df['a'].apply(my_func2, e=2)\n",
    "df['a'].apply(my_func2, e=3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b838898148bb9694"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 apply函数作用于 DataFrame对象"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4b2bb32c226f21f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 细节: apply()函数作用于DF对象, 默认传入的是: axis=0(整列)数据, 不是像Series一样, 逐个元素传递的. \n",
    "# 1. 把上述的 my_func1()函数, 作用到DF对象.\n",
    "df.apply(my_func1)\n",
    "\n",
    "\n",
    "# 2. 自定义函数my_func3(), 看看df对象到底传入的是什么.\n",
    "def my_func3(x):\n",
    "    print(f'x的内容: {x}')\n",
    "    print(f'x的类型: {type(x)}')\n",
    "\n",
    "\n",
    "# 3. 调用上述的my_func3(), 作用于: df对象\n",
    "# df.apply(my_func3)          # 默认传入的就是: 整列(Series对象)\n",
    "# df.apply(my_func3, axis=0)  # 0:列, 1:行.  该行代码, 效果同上.\n",
    "df.apply(my_func3, axis=1)  # 传入整行"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d2a0d21b73dd5e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 4. 如下是一种错误示范, 目的是引出稍后要讲解的: 函数的向量化\n",
    "def avg_3(x, y, z):\n",
    "    return (x + y + z) / 3\n",
    "\n",
    "\n",
    "# 无意义, 只是给大家演示下, 如何解决上述的哪个函数出现的问题.\n",
    "def avg_3_mod(x):\n",
    "    n1 = x[0]\n",
    "    n2 = x[1]\n",
    "    n3 = x[2]\n",
    "    return (n1 + n2 + n3) / 3\n",
    "\n",
    "\n",
    "# df.apply(avg_3)         # 报错的, 因为直接传入的是: 整列的数据.\n",
    "df.apply(avg_3_mod)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9421d4e8e6616503"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 apply()函数案例-泰坦尼克号数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbcb8ba10c48e5da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 需求: 自定义函数, 分别计算 泰坦尼克号数据集 某列的缺失值个数, 某列的缺失值占比, 某列的非缺失值占比.\n",
    "# 1. 读取数据源, 获取df对象.\n",
    "titanic = pd.read_csv('data/titanic_train.csv')\n",
    "titanic.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ca5f509f900faa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. 定义函数, 实现各种需求.\n",
    "# 需求1: count_missing(vec), 计算某列的缺失值个数\n",
    "def count_missing(vec):\n",
    "    # vec就是接收到的 df对象的 某列 或者 某行数据\n",
    "    return pd.isnull(vec).sum()\n",
    "\n",
    "\n",
    "# 需求2: prop_missing(vec), 计算某列中缺失值占比\n",
    "def prop_missing(vec):\n",
    "    # 缺失值占比公式: 某列缺失值数量 / 某列的元素总个数\n",
    "    # return pd.isnull(vec).sum() / vec.size\n",
    "    return count_missing(vec) / vec.size\n",
    "\n",
    "\n",
    "# 需求3: prop_complete(vec), 计算某列的 非缺失值占比.  # vector\n",
    "def prop_complete(vec):\n",
    "    # 非缺失值占比: 1 - 缺失值占比\n",
    "    return 1 - prop_missing(vec)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38ee373e7c648c6c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3. 测试上述的函数.\n",
    "# 默认: axis = 0, 即: 以列的形式传入的\n",
    "titanic.apply(count_missing)  # 传入的时候一定不要加小括号, 我们传入的是: 函数对象\n",
    "titanic.apply(prop_missing)  # 某列缺失值占比\n",
    "titanic.apply(prop_complete)  # 某列非缺失值占比\n",
    "\n",
    "# 以行的形式传入\n",
    "titanic.apply(count_missing, axis=1)  # 1代表: 行, 某行缺失值数量\n",
    "titanic.apply(prop_missing, axis=1)  # 某行缺失值占比\n",
    "titanic.apply(prop_complete, axis=1)  # 某行非缺失值占比\n",
    "\n",
    "titanic.shape  # 维度(行列数), (891, 12)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c208330825f9ef59"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 向量化函数介绍, np.vectorize"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "429d3c80bd5830ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. 创建df对象, 给两列值.\n",
    "df = pd.DataFrame({'a': [10, 20, 30], 'b': [20, 30, 40]})\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b9b02b21a7b2814"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. 定义函数 avg_2, 计算上述的平均值.\n",
    "def avg_2(x, y):\n",
    "    return (x + y) / 2\n",
    "\n",
    "\n",
    "# 调用上述的自定义函数\n",
    "avg_2(df['a'], df['b'])  # 无问题"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61512ef47688b23a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3. 改造上述的代码, 程序出问题了.\n",
    "def avg_2_mod(x, y):\n",
    "    if x == 20:  # 这里会出错, 因为: x是向量(简单理解: 一堆值), 20是标量(1个值)\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return (x + y) / 2\n",
    "\n",
    "\n",
    "# 调用上述的自定义函数\n",
    "# avg_2_mod(df['a'], df['b'])     # 有问题\n",
    "\n",
    "# 解决思路: 通过np.vectorize将上述的函数转成: 向量化函数, 如果函数中遇到向量了, 则内部会自动遍历.\n",
    "# 写法1: np.vectorize修饰函数, 获取: 向量化后的函数.\n",
    "avg_2_mod_vec = np.vectorize(avg_2_mod)\n",
    "avg_2_mod_vec(df['a'], df['b'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d14ee8ecd899b86a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 写法2: 装饰器方式, 装饰 函数.\n",
    "@np.vectorize\n",
    "def avg_2_mod(x, y):\n",
    "    if x == 20:  # 这里会出错, 因为: x是向量(简单理解: 一堆值), 20是标量(1个值)\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return (x + y) / 2\n",
    "\n",
    "\n",
    "# 调用上述的自定义函数\n",
    "avg_2_mod(df['a'], df['b'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8034d47696b89176"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.5 apply()函数, 接收 lambda表达式写的 匿名函数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b989acaf712cb2b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 细节: 如果需求非常简单, 我们就没有必要再去定义函数了, 直接传入 lambda表达式即可.\n",
    "# 需求: df的每个元素, 变成其平方值.\n",
    "# 1. 创建df对象, 给两列值.\n",
    "df = pd.DataFrame({'a': [10, 20, 30], 'b': [20, 30, 40]})\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9143a732a2b94cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 方式1: 普通写法.\n",
    "def my_fun1(x):\n",
    "    return x ** 2\n",
    "\n",
    "\n",
    "# 调用函数\n",
    "df.apply(my_fun1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "952a044286925e57"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 方式2: lambda 表达式\n",
    "df.apply(lambda x: x ** 2)\n",
    "df.apply(lambda x: x ** 3)\n",
    "df.apply(lambda x: x + 1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57780705b4435b04"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 数据分组处理"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c443d4ac551b7724"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 分组聚合,  n => 1 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0ab74b383bdd65d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 格式: groupby([分组字段1, 分组字段2...])[[要聚合运算的字段1, 字段2...]].聚合函数名()\n",
    "# 1. 加载数据源, 获取df对象\n",
    "df = pd.read_csv('data/gapminder.tsv', sep='\\t')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44d432d99ca872ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. 演示 分组聚合 操作, 即: 分完组, 聚合计算后, 每组都只会获取 1个 结果.\n",
    "# 需求1: 统计每年的 平均寿命.\n",
    "df.groupby('year').lifeExp.mean()\n",
    "\n",
    "# 需求2: 针对于上述的结果, 我们还可以手动, 逐个计算每年的平均寿命.\n",
    "# 1. 看看有哪些年.\n",
    "df['year'].unique()  # 一共有 12个 年份, 从1952年开始统计的. \n",
    "\n",
    "# 2. 手动计算第1组, 即: 1952年的平均寿命\n",
    "df[df.year == 1952].lifeExp.mean()  # 49.05761971830987\n",
    "\n",
    "# 3. 其实上述的分组, 内部就是逐个的计算每年的平均寿命, 然后组合到一起."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9528882775bd2fc8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 需求3: 上述我们使用的是pandas的聚合函数, 我们还可以使用 Numpy的聚合函数\n",
    "# 例如: 统计各个大洲的 平均寿命.\n",
    "df.groupby('continent').lifeExp.mean()  # mean: pandas的函数\n",
    "df.groupby('continent').lifeExp.agg(np.mean)  # 效果同上, np.mean 是 numpy的函数\n",
    "\n",
    "df.groupby('continent').agg({'lifeExp': 'mean'})  # pandas的聚合函数\n",
    "df.groupby('continent').agg({'lifeExp': np.mean})  # numpy的聚合函数\n",
    "\n",
    "# 使用aggregate() 和 agg()函数效果是一样的.\n",
    "df.groupby('continent').aggregate({'lifeExp': 'mean'})  # pandas的聚合函数\n",
    "df.groupby('continent').aggregate({'lifeExp': np.mean})  # numpy的聚合函数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f4edb1d05145e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 需求4: 使用自定义的函数, 完成: 计算平均值.\n",
    "def my_mean(col):\n",
    "    # return col.mean()\n",
    "    return col.sum() / col.size  # 总和 / 个数\n",
    "\n",
    "# 传入我们自定义的函数, 计算平均值\n",
    "df.groupby('continent').lifeExp.agg(my_mean)  # 不要加小括号, 这里传入的是: 函数对象."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de5120a7c3a7229a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 需求5: 计算全球平均预期寿命的平均值 和 分组之后的平均值做差值.\n",
    "# 大白话: 就是上述算出来的各组平均值 和 全球总预期寿命平均值的差值.\n",
    "def my_mean_diff(col, diff_value):\n",
    "    # return my_mean(col) - diff_value\n",
    "    return col.mean() - diff_value\n",
    "\n",
    "\n",
    "# 1. 获取全球平均预期寿命.\n",
    "global_lifeExp_mean = df.lifeExp.mean()\n",
    "\n",
    "# 2. 完成上述的需求. \n",
    "df.groupby('continent').lifeExp.agg(my_mean_diff, diff_value=global_lifeExp_mean)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50443280e42512a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 需求6: agg()函数, 同时传入多个函数.\n",
    "# 例如: 按年计算LifeExp的 非零个数, 平均值 和 标准差.\n",
    "df.groupby('year').lifeExp.agg([np.count_nonzero, np.mean, np.std])\n",
    "\n",
    "# 例如: 计算多列值的不同需求, 按年统计, 平均寿命, 最大人口, 最小GDP\n",
    "df.groupby('year').agg({'lifeExp': 'mean', 'pop': 'max', 'gdpPercap': 'min'})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a533fcd72ed81a16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 分组转换.    n => n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cba87c8220333e50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. 查看数据源. \n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ab6117d58c001ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. 需求1: 自定义函数, 计算某列的 Z分数(标准分数).  公式: (x - x的平均值) / 标准差\n",
    "def my_zscore(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "# 3. 按年分组, 计算 LifeExp列的, zscore标准分数.\n",
    "df.groupby('year').lifeExp.transform(my_zscore)     # 1704\n",
    "# df.shape                                          # 维度: 行列数, (1704, 6)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f7ae8540e491814"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 需求2: 按照性别分组, 计算男女(male, female)各组的平均消费, 然后进行填充.\n",
    "# 1. 读取数据源, 获取df对象.\n",
    "# sample(): 随机取样的, 参1: 取几个值.  参2: 随机种子, 如果种子一样, 每次获取的结果都是一样的. \n",
    "tips_10 = pd.read_csv('data/tips.csv').sample(10, random_state=20)\n",
    "tips_10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fba81878b0d9adb0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. 人为的给 total_bill列, 创建几个空值.\n",
    "# tips_10.loc[[87, 153, 128], 'total_bill'] = np.NaN       # 可以实现需求, 但是不好, 空值我们都固定了.\n",
    "# np.random.permutation(tips_10.index)  根据 tips_10 这个df对象的索引, 对其进行随机打散\n",
    "tips_10.loc[np.random.permutation(tips_10.index)[:4] , 'total_bill'] = np.NaN\n",
    "\n",
    "# 3. 查看各列的非空值统计情况.\n",
    "tips_10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab0c327c078210c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 4. 我不想用 total_bill列的平均值, 来填充该列的空值, 因为: 男, 女一般消费习惯不一样.\n",
    "# 我想要做的事情是, 计算出 男, 女各自的 平均总消费, 然后按照性别来填充. \n",
    "# 自定义函数, 用于实现, 用该列的平均值, 来填充数据.\n",
    "def my_fillna(col):\n",
    "    return col.fillna(col.mean())\n",
    "\n",
    "# 调用上述的函数, 填充即可.  transform(): 分组转换, 即: 源数据无论多少条, 处理后还是多少条, 类似于SQL的窗口函数.\n",
    "tips_10.groupby('sex').total_bill.transform(my_fillna)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1053832234f68957"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 分组过滤"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65626bb00ab328d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. 加载数据源.\n",
    "tips = pd.read_csv('data/tips.csv')\n",
    "tips\n",
    "\n",
    "# 2. 查看吃饭人数的分布情况\n",
    "tips['size'].value_counts()\n",
    "\n",
    "# 3. 发现, 1个人, 5个人, 6个人吃饭的次数还是较少的, 我们过滤掉这部分数据. \n",
    "tmp_df = tips.groupby('size').filter(lambda x: x['size'].count() > 10)\n",
    "\n",
    "# 4. 过滤完后, 查看过滤后的结果.\n",
    "tmp_df['size'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1d942feb7753d97"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4 分组对象 DataFrameGroupBy演示 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a9a695022da309c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. 加载数据源, 获取df对象.\n",
    "df = pd.read_csv('data/tips.csv').sample(10, random_state=20)   # 随机种子一致, 每次抽取的结果都是一样的\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62baf7e783e56de9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. 根据性别分组, 获取分组对象.\n",
    "grouped = df.groupby('sex')       # DataFrameGroupBy 数据类型\n",
    "\n",
    "# 3. 通过 groups 属性查看计算过的分组. \n",
    "grouped.groups      # {'Female': [209, 128, 132], 'Male': [87, 236, 153, 172, 237, 129, 13]}\n",
    "\n",
    "# 4. 在DataFrameGroupBy基础上, 可以直接计算.\n",
    "grouped.mean()      # 等价于: df.groupby('sex').mean() \n",
    "\n",
    "# 5. 通过 get_group 获取分组.\n",
    "# grouped[0]                # 错误写法\n",
    "grouped.get_group('Male')   # 正确写法............\n",
    "\n",
    "# 6. 遍历groupby对象, 获取所有的分组\n",
    "for sex_group in grouped:\n",
    "    print(sex_group)        # 查看分组对象, 各组的数据.\n",
    "    \n",
    "# 7. 需求: 按性别和用餐时间分组, 计算小费数据的平均值.\n",
    "df.groupby(['sex', 'time']).tip.mean()\n",
    "df.groupby(['sex', 'time'], as_index=False).tip.mean()  # as_index=False 不把分组字段作为 索引列"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51a7e677a0b2eb56"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
